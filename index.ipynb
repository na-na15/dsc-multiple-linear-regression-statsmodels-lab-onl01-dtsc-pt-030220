{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression in Statsmodels - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll practice fitting a multiple linear regression model on the Boston Housing dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Determine if it is necessary to perform normalization/standardization for a specific model or set of data\n",
    "* Use standardization/normalization on features of a dataset\n",
    "* Identify if it is necessary to perform log transformations on a set of features\n",
    "* Perform log transformations on different features of a dataset\n",
    "* Use statsmodels to fit a multiple linear regression model\n",
    "* Evaluate a linear regression model by using statistical performance metrics pertaining to overall model and specific parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pre-processed the Boston Housing data again. This time, however, we did things slightly different:\n",
    "- We dropped `'ZN'` and `'NOX'` completely \n",
    "- We categorized `'RAD'` in 3 bins and `'TAX'` in 4 bins\n",
    "- We transformed `'RAD'` and `'TAX'` to dummy variables and dropped the first variable to eliminate multicollinearity\n",
    "- We used min-max-scaling on `'B'`, `'CRIM'`, and `'DIS'` (and log transformed all of them first, except `'B'`)\n",
    "- We used standardization on `'AGE'`, `'INDUS'`, `'LSTAT'`, and `'PTRATIO'` (and log transformed all of them first, except for `'AGE'`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "boston_features = boston_features.drop(['NOX', 'ZN'],axis=1)\n",
    "\n",
    "# First, create bins for based on the values observed. 3 values will result in 2 bins\n",
    "bins = [0, 6, 24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# First, create bins for based on the values observed. 4 values will result in 3 bins\n",
    "bins = [0, 270, 360, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix='TAX', drop_first=True)\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix='RAD', drop_first=True)\n",
    "boston_features = boston_features.drop(['RAD','TAX'], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = boston_features['AGE']\n",
    "b = boston_features['B']\n",
    "logcrim = np.log(boston_features['CRIM'])\n",
    "logdis = np.log(boston_features['DIS'])\n",
    "logindus = np.log(boston_features['INDUS'])\n",
    "loglstat = np.log(boston_features['LSTAT'])\n",
    "logptratio = np.log(boston_features['PTRATIO'])\n",
    "\n",
    "# Min-Max scaling\n",
    "boston_features['B'] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features['CRIM'] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "boston_features['DIS'] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "# Standardization\n",
    "boston_features['AGE'] = (age-np.mean(age))/np.sqrt(np.var(age))\n",
    "boston_features['INDUS'] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "boston_features['LSTAT'] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "boston_features['PTRATIO'] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RAD_(6, 24]</th>\n",
       "      <th>TAX_(270, 360]</th>\n",
       "      <th>TAX_(360, 712]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.704344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.575</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>-1.443977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.153211</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.421</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153134</td>\n",
       "      <td>-0.263239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.185</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>-0.230278</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171005</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.998</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250315</td>\n",
       "      <td>-1.778965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.147</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>0.165279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM     INDUS  CHAS     RM       AGE       DIS   PTRATIO         B  \\\n",
       "0  0.000000 -1.704344   0.0  6.575 -0.120013  0.542096 -1.443977  1.000000   \n",
       "1  0.153211 -0.263239   0.0  6.421  0.367166  0.623954 -0.230278  1.000000   \n",
       "2  0.153134 -0.263239   0.0  7.185 -0.265812  0.623954 -0.230278  0.989737   \n",
       "3  0.171005 -1.778965   0.0  6.998 -0.809889  0.707895  0.165279  0.994276   \n",
       "4  0.250315 -1.778965   0.0  7.147 -0.511180  0.707895  0.165279  1.000000   \n",
       "\n",
       "      LSTAT  RAD_(6, 24]  TAX_(270, 360]  TAX_(360, 712]  \n",
       "0 -1.275260            0               1               0  \n",
       "1 -0.263711            0               0               0  \n",
       "2 -1.627858            0               0               0  \n",
       "3 -2.153192            0               0               0  \n",
       "4 -1.162114            0               0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'INDUS', 'CHAS', 'RM', 'AGE', 'DIS', 'PTRATIO', 'B', 'LSTAT',\n",
       "       'RAD_(6, 24]', 'TAX_(270, 360]', 'TAX_(360, 712]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = boston_features.rename(columns={\"RAD_(6, 24]\": \"RAD1\", \"TAX_(270, 360]\": \"TAX1\",\"TAX_(360, 712]\":\"TAX2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a linear model in statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# formula = \"LSTAT ~ CRIM+INDUS+CHAS+RM+AGE+DIS+PTRATIO+B+RAD1+TAX1+TAX2\"\n",
    "# model = ols(formula= formula, data=new_data).fit()\n",
    "outcome = 'LSTAT'\n",
    "predictors = new_data.drop('LSTAT', axis=1)\n",
    "pred_sum = \"+\".join(predictors.columns)\n",
    "formula1 = outcome + \"~\" + pred_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>LSTAT</td>      <th>  R-squared:         </th> <td>   0.698</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.691</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   103.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 May 2020</td> <th>  Prob (F-statistic):</th> <td>1.07e-120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:55:53</td>     <th>  Log-Likelihood:    </th> <td> -415.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   854.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   494</td>      <th>  BIC:               </th> <td>   905.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    4.1990</td> <td>    0.359</td> <td>   11.699</td> <td> 0.000</td> <td>    3.494</td> <td>    4.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>    0.5981</td> <td>    0.268</td> <td>    2.235</td> <td> 0.026</td> <td>    0.072</td> <td>    1.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>     <td>    0.1027</td> <td>    0.046</td> <td>    2.238</td> <td> 0.026</td> <td>    0.013</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>   -0.2183</td> <td>    0.101</td> <td>   -2.166</td> <td> 0.031</td> <td>   -0.416</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>   -0.6819</td> <td>    0.042</td> <td>  -16.296</td> <td> 0.000</td> <td>   -0.764</td> <td>   -0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>       <td>    0.4021</td> <td>    0.041</td> <td>    9.831</td> <td> 0.000</td> <td>    0.322</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>    0.5471</td> <td>    0.235</td> <td>    2.330</td> <td> 0.020</td> <td>    0.086</td> <td>    1.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>    0.0517</td> <td>    0.031</td> <td>    1.688</td> <td> 0.092</td> <td>   -0.008</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>   -0.4466</td> <td>    0.124</td> <td>   -3.609</td> <td> 0.000</td> <td>   -0.690</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD1</th>      <td>   -0.0123</td> <td>    0.086</td> <td>   -0.144</td> <td> 0.886</td> <td>   -0.180</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX1</th>      <td>   -0.0100</td> <td>    0.076</td> <td>   -0.131</td> <td> 0.896</td> <td>   -0.160</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX2</th>      <td>   -0.0079</td> <td>    0.090</td> <td>   -0.088</td> <td> 0.930</td> <td>   -0.184</td> <td>    0.168</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>163.499</td> <th>  Durbin-Watson:     </th> <td>   1.092</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 799.337</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.343</td>  <th>  Prob(JB):          </th> <td>2.67e-174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.541</td>  <th>  Cond. No.          </th> <td>    110.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  LSTAT   R-squared:                       0.698\n",
       "Model:                            OLS   Adj. R-squared:                  0.691\n",
       "Method:                 Least Squares   F-statistic:                     103.7\n",
       "Date:                Thu, 28 May 2020   Prob (F-statistic):          1.07e-120\n",
       "Time:                        10:55:53   Log-Likelihood:                -415.29\n",
       "No. Observations:                 506   AIC:                             854.6\n",
       "Df Residuals:                     494   BIC:                             905.3\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      4.1990      0.359     11.699      0.000       3.494       4.904\n",
       "CRIM           0.5981      0.268      2.235      0.026       0.072       1.124\n",
       "INDUS          0.1027      0.046      2.238      0.026       0.013       0.193\n",
       "CHAS          -0.2183      0.101     -2.166      0.031      -0.416      -0.020\n",
       "RM            -0.6819      0.042    -16.296      0.000      -0.764      -0.600\n",
       "AGE            0.4021      0.041      9.831      0.000       0.322       0.483\n",
       "DIS            0.5471      0.235      2.330      0.020       0.086       1.008\n",
       "PTRATIO        0.0517      0.031      1.688      0.092      -0.008       0.112\n",
       "B             -0.4466      0.124     -3.609      0.000      -0.690      -0.203\n",
       "RAD1          -0.0123      0.086     -0.144      0.886      -0.180       0.156\n",
       "TAX1          -0.0100      0.076     -0.131      0.896      -0.160       0.140\n",
       "TAX2          -0.0079      0.090     -0.088      0.930      -0.184       0.168\n",
       "==============================================================================\n",
       "Omnibus:                      163.499   Durbin-Watson:                   1.092\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              799.337\n",
       "Skew:                          -1.343   Prob(JB):                    2.67e-174\n",
       "Kurtosis:                       8.541   Cond. No.                         110.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ols(formula= formula1, data=new_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the same model in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_ols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-e98399703711>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here - Check that the coefficients and intercept are the same as those from Statsmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_ols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LSTAT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlinreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_ols' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here - Check that the coefficients and intercept are the same as those from Statsmodels\n",
    "from sklearn.linear_model import LinearRegression\n",
    "y = data_ols['LSTAT']\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(predictors, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the coefficients for PTRATIO, PTRATIO, LSTAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRIM: per capita crime rate by town\n",
    "- INDUS: proportion of non-retail business acres per town\n",
    "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- RM: average number of rooms per dwelling\n",
    "- AGE: proportion of owner-occupied units built prior to 1940\n",
    "- DIS: weighted distances to five Boston employment centres\n",
    "- RAD: index of accessibility to radial highways\n",
    "- TAX: full-value property-tax rate per $10,000\n",
    "- PTRATIO: pupil-teacher ratio by town\n",
    "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of African American individuals by town\n",
    "- LSTAT: % lower status of the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the house price given the following characteristics (before manipulation!!)\n",
    "\n",
    "Make sure to transform your variables as needed!\n",
    "\n",
    "- CRIM: 0.15\n",
    "- INDUS: 6.07\n",
    "- CHAS: 1        \n",
    "- RM:  6.1\n",
    "- AGE: 33.2\n",
    "- DIS: 7.6\n",
    "- PTRATIO: 17\n",
    "- B: 383\n",
    "- LSTAT: 10.87\n",
    "- RAD: 8\n",
    "- TAX: 284"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Congratulations! You pre-processed the Boston Housing data using scaling and standardization. You also fitted your first multiple linear regression model on the Boston Housing data using statsmodels and scikit-learn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
